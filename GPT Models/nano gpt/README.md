# âœï¸ nanoGPT: Character-Level Transformer on Shakespeare

This project is a **from-scratch implementation** of Andrej Karpathyâ€™s [nanoGPT](https://github.com/karpathy/nanoGPT) model using PyTorch. It trains a character-level language model on **Shakespeare's works** and learns to generate text in that style.

---

## ğŸ¯ Goal

To deeply understand how GPT-style transformers work by re-implementing a minimal version. This version achieves **low training loss** and generates coherent English textâ€”showing that even small transformer models can learn meaningful language structure.

---

## ğŸ§  Model Summary

- **Transformer architecture** (multi-head self-attention)
- Trained on raw character sequences (no tokenization)
- Learned to predict the **next character** in a Shakespearean dataset
- Implemented manually: attention, layer normalization, embeddings, MLPs

---

## ğŸ“‚ File Structure


