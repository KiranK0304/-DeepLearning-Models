# ✍️ nanoGPT: Character-Level Transformer on Shakespeare

This project is a **from-scratch implementation** of Andrej Karpathy’s [nanoGPT](https://github.com/karpathy/nanoGPT) model using PyTorch. It trains a character-level language model on **Shakespeare's works** and learns to generate text in that style.

---

## 🎯 Goal

To deeply understand how GPT-style transformers work by re-implementing a minimal version. This version achieves **low training loss** and generates coherent English text—showing that even small transformer models can learn meaningful language structure.

---

## 🧠 Model Summary

- **Transformer architecture** (multi-head self-attention)
- Trained on raw character sequences (no tokenization)
- Learned to predict the **next character** in a Shakespearean dataset
- Implemented manually: attention, layer normalization, embeddings, MLPs

---

## 📂 File Structure


